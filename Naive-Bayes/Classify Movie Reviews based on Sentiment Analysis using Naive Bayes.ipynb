{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Movie Reviews based on Sentiment Analysis using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict whether a review is negative or positive, based on the text data set using Naive Bayes and do some Natural Language Processing to extract features to train the algorithm from the text of the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains movie reviews along with their associated binary sentiment polarity labels formatted CSV file. Each row contains the text of the review, as well as a number indicating whether the tone of the review is positive(1) or negative(-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading In Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"C:/Users/i7/csv/naive/train.csv\", 'r', encoding='latin-1') as file:\n",
    "    reviews = list(csv.reader(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Word Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating features from text with split the text up into words. Each word in a review will then be a feature that can then work with. (split the reviews based on whitespace.)\n",
    "\n",
    "Then count up how many times each word occurs in the negative reviews, and how many times each word occurs in the positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_text[:100]: story of a man who has unnatural feelings for a pig. starts out with a opening scene that is a terri\n",
      "positive_text[:100]: bromwell high is a cartoon comedy. it ran at the same time as some other programs about school life,\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def get_text(reviews, score):\n",
    "    # Join together the text in the reviews for a particular tone.\n",
    "    # We lowercase to avoid \"Not\" and \"not\" being seen as different words, for example.\n",
    "    return \" \".join([r[0].lower() for r in reviews if r[1] == str(score)])\n",
    "\n",
    "def count_text(text):\n",
    "    # Split text into words based on whitespace.  Simple but effective.\n",
    "    words = re.split(\"\\s+\", text)\n",
    "    # Count up the occurence of each word.\n",
    "    return Counter(words)\n",
    "\n",
    "negative_text = get_text(reviews, -1)\n",
    "positive_text = get_text(reviews, 1)\n",
    "# Generate word counts for negative tone.\n",
    "negative_counts = count_text(negative_text)\n",
    "# Generate word counts for positive tone.\n",
    "positive_counts = count_text(positive_text)\n",
    "\n",
    "print(\"negative_text[:100]:\", negative_text[:100])\n",
    "print(\"positive_text[:100]:\", positive_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the word counts to probabilities and multiply them out to get the predicted classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews[0][0]: Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n",
      "neg_pred: 0.0\n",
      "pos_pred: 0.0\n"
     ]
    }
   ],
   "source": [
    "def get_y_count(score):\n",
    "    # Compute the count of each classification occuring in the data.\n",
    "    return len([r for r in reviews if r[1] == str(score)])\n",
    "\n",
    "# Split the counts to use for smoothing when computing the prediction.\n",
    "positive_review_count = get_y_count(1)\n",
    "negative_review_count = get_y_count(-1)\n",
    "\n",
    "# These are the class probabilities.\n",
    "prob_positive = positive_review_count / len(reviews)\n",
    "#print(prob_positive)\n",
    "prob_negative = negative_review_count / len(reviews)\n",
    "#print(prob_negative)\n",
    "\n",
    "def make_class_prediction(text, counts, class_prob, class_count):\n",
    "    prediction = 1\n",
    "    text_counts = Counter(re.split(\"\\s+\", text))\n",
    "    for word in text_counts:\n",
    "        prediction *=  float(text_counts.get(word) * ((counts.get(word, 0) + 1)) / (sum(counts.values()) + class_count))\n",
    "    return prediction * class_prob\n",
    "\n",
    "# The probabilities themselves aren't very useful -- make classification decision based on which value is greater.\n",
    "print(\"reviews[0][0]:\", reviews[0][0])\n",
    "\n",
    "neg_pred = make_class_prediction(reviews[0][0], negative_counts, prob_negative, negative_review_count)\n",
    "print(\"neg_pred:\", neg_pred)\n",
    "\n",
    "pos_pred = make_class_prediction(reviews[0][0], positive_counts, prob_positive, positive_review_count)\n",
    "print(\"pos_pred:\", pos_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting The Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the probabilities on the reviews in test.csv. if it's not, it will get misleadingly good results if predict on the reviews in train.csv, because the probabilities were generated from it (and this, the algorithm has prior knowledge about the data it’s predicting on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting good results on the training set could mean that the model is overfit, and is just picking up random noise. Only testing on a set that the model wasn’t trained with can tell that if it’s performing properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions[:5]: [1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def make_decision(text, make_class_prediction):\n",
    "    # Compute the negative and positive probabilities.\n",
    "    negative_prediction = make_class_prediction(text, negative_counts, prob_negative, negative_review_count)\n",
    "    positive_prediction = make_class_prediction(text, positive_counts, prob_positive, positive_review_count)\n",
    "\n",
    "    # Assign a classification based on which probability is greater.\n",
    "    if negative_prediction > positive_prediction:\n",
    "        return -1\n",
    "    return 1\n",
    "\n",
    "with open(\"C:/Users/i7/csv/naive/test.csv\", 'r', encoding='latin-1') as file:\n",
    "    test = list(csv.reader(file))\n",
    "\n",
    "predictions = [make_decision(r[0], make_class_prediction) for r in test]\n",
    "print(\"predictions[:5]:\", predictions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Prediction Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute error using the area under the ROC curve. This will tell how “good” the model is – closer to 1 means that the model is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.559\n"
     ]
    }
   ],
   "source": [
    "actual = [int(r[1]) for r in test]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate the roc curve using scikits-learn.\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "\n",
    "# Measure the area under the curve.  The closer to 1, the \"better\" the predictions.\n",
    "print(\"AUC:\", metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "# do some Natural Language Processing to extract features\n",
    "# Generate counts from text using a vectorizer.  There are other vectorizers available, and lots of options that can set.\n",
    "# This performs step of computing word counts.\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_features = vectorizer.fit_transform([r[0] for r in reviews])\n",
    "test_features = vectorizer.transform([r[0] for r in test])\n",
    "\n",
    "# Fit a naive bayes model to the training data.\n",
    "# This will train the model using the word counts we compute, and the existing classifications in the training set.\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_features, [int(r[1]) for r in reviews])\n",
    "\n",
    "# Use the model to predict classifications for the test features.\n",
    "predictions = nb.predict(test_features)\n",
    "\n",
    "# Compute the error. It is slightly different from the model before because the internals of this process work differently from our implementation.\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "print(\"AUC:\", metrics.auc(fpr, tpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
